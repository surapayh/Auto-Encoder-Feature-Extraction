# Auto-Encoder-Feature-Extraction
Autoencoders are a class of [Unsupervised Learning](https://en.wikipedia.org/wiki/Unsupervised_learning#:~:text=Unsupervised%20learning%20(UL)%20is%20a,tagged%20by%20a%20human%2C%20eg.) algorithms. The goal of the autoencoders is not classification. Autoencoders are trained to learn [Identity function](https://en.wikipedia.org/wiki/Identity_function). The weights of the network are optimized to produce the output which is same as the input. Typically, [Mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error#:~:text=In%20statistics%2C%20the%20mean%20squared,values%20and%20the%20actual%20value.) is used as the loss function. The major advantage of such a network is it helps in dimensionality reduction of the input data. It is very essential in computationally intense calculations to identify the dimensions or features which are of more importance than the features which have a very high correlation. The advantage of Autoencoders is that they can model even complex nonlinear functions. Autoencoder typically consists of an Encoder(it generally compresses the input to a lateral-space representation) and a Decoder(it reconstructs the actual input from the generated lateral-space representation). This process generally forces the network to learn the patterns present in the data. Autoencoders can be used as [Feature extractors](https://deepai.org/machine-learning-glossary-and-terms/feature-extraction#:~:text=Feature%20extraction%20is%20the%20name,describing%20the%20original%20data%20set.). These features that are extracted are not designed explicitly and also can be used in [Feed forward networks](https://en.wikipedia.org/wiki/Feedforward_neural_network) to improve the classification quality.
